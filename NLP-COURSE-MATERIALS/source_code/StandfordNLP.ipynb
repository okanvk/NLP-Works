{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanfordnlp\n",
    "#http://tools.nlp.itu.edu.tr/Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanfordnlp.download('tr', version='0.2.0')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/okanciftci/stanfordnlp_resources/tr_imst_models/tr_imst_tokenizer.pt', 'lang': 'tr', 'shorthand': 'tr_imst', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/okanciftci/stanfordnlp_resources/tr_imst_models/tr_imst_lemmatizer.pt', 'lang': 'tr', 'shorthand': 'tr_imst', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/okanciftci/stanfordnlp_resources/tr_imst_models/tr_imst_tagger.pt', 'pretrain_path': '/Users/okanciftci/stanfordnlp_resources/tr_imst_models/tr_imst.pretrain.pt', 'lang': 'tr', 'shorthand': 'tr_imst', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "nlp = stanfordnlp.Pipeline(processors='tokenize,lemma,pos', lang='tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Sentence 1 tokens =======\n",
      "index:   1\ttoken: Bütün\n",
      "index:   2\ttoken: insanlar\n",
      "index:   3\ttoken: hür\n",
      "index:   4\ttoken: ,\n",
      "index:   5\ttoken: haysiyet\n",
      "index:   6\ttoken: ve\n",
      "index:   7\ttoken: haklar\n",
      "index:   8\ttoken: bakımından\n",
      "index:   9\ttoken: eşit\n",
      "index:  10\ttoken: doğarlar\n",
      "index:  11\ttoken: .\n",
      "====== Sentence 2 tokens =======\n",
      "index:   1\ttoken: Akıl\n",
      "index:   2\ttoken: ve\n",
      "index:   3\ttoken: vicdana\n",
      "index:   4\ttoken: sahiptirler\n",
      "index:   5\ttoken: ve\n",
      "index:   6\ttoken: birbirlerine\n",
      "index:   7\ttoken: karşı\n",
      "index:   8\ttoken: kardeşlik\n",
      "index:   9\ttoken: zihniyeti\n",
      "index:  10\ttoken: ile\n",
      "index:  11\ttoken: hareket\n",
      "index:  12\ttoken: etmelidirler\n",
      "index:  13\ttoken: .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Bütün insanlar hür, haysiyet ve haklar bakımından eşit doğarlar. Akıl ve vicdana sahiptirler ve birbirlerine karşı kardeşlik zihniyeti ile hareket etmelidirler.\")\n",
    "for i, sentence in enumerate(doc.sentences):\n",
    "    print(f\"====== Sentence {i+1} tokens =======\")\n",
    "    print(*[f\"index: {token.index.rjust(3)}\\ttoken: {token.text}\" for token in sentence.tokens], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: Bütün \tlemma: bütün\n",
      "word: insanlar \tlemma: insan\n",
      "word: hür \tlemma: hür\n",
      "word: , \tlemma: ,\n",
      "word: haysiyet \tlemma: haysiyet\n",
      "word: ve \tlemma: ve\n",
      "word: haklar \tlemma: hak\n",
      "word: bakımından \tlemma: bakım\n",
      "word: eşit \tlemma: eşit\n",
      "word: doğarlar \tlemma: doğ\n",
      "word: . \tlemma: .\n",
      "word: Akıl \tlemma: akıl\n",
      "word: ve \tlemma: ve\n",
      "word: vicdana \tlemma: vicdan\n",
      "word: sahiptirler \tlemma: sahip\n",
      "word: ve \tlemma: ve\n",
      "word: birbirlerine \tlemma: birbiri\n",
      "word: karşı \tlemma: karşı\n",
      "word: kardeşlik \tlemma: kardeşlik\n",
      "word: zihniyeti \tlemma: zihniyet\n",
      "word: ile \tlemma: ile\n",
      "word: hareket \tlemma: hareket\n",
      "word: etmelidirler \tlemma: et\n",
      "word: . \tlemma: .\n"
     ]
    }
   ],
   "source": [
    "print(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: Bütün \tupos: ADJ\txpos: Adj\n",
      "word: insanlar \tupos: NOUN\txpos: Noun\n",
      "word: hür \tupos: ADJ\txpos: NAdj\n",
      "word: , \tupos: PUNCT\txpos: Punc\n",
      "word: haysiyet \tupos: NOUN\txpos: Noun\n",
      "word: ve \tupos: CCONJ\txpos: Conj\n",
      "word: haklar \tupos: NOUN\txpos: Noun\n",
      "word: bakımından \tupos: NOUN\txpos: Noun\n",
      "word: eşit \tupos: ADJ\txpos: Adj\n",
      "word: doğarlar \tupos: VERB\txpos: Verb\n",
      "word: . \tupos: PUNCT\txpos: Punc\n",
      "word: Akıl \tupos: NOUN\txpos: Noun\n",
      "word: ve \tupos: CCONJ\txpos: Conj\n",
      "word: vicdana \tupos: NOUN\txpos: Noun\n",
      "word: sahiptirler \tupos: VERB\txpos: Verb\n",
      "word: ve \tupos: CCONJ\txpos: Conj\n",
      "word: birbirlerine \tupos: PRON\txpos: Quant\n",
      "word: karşı \tupos: ADV\txpos: Adverb\n",
      "word: kardeşlik \tupos: NOUN\txpos: Noun\n",
      "word: zihniyeti \tupos: NOUN\txpos: Noun\n",
      "word: ile \tupos: CCONJ\txpos: Conj\n",
      "word: hareket \tupos: NOUN\txpos: Noun\n",
      "word: etmelidirler \tupos: VERB\txpos: Verb\n",
      "word: . \tupos: PUNCT\txpos: Punc\n"
     ]
    }
   ],
   "source": [
    "print(*[f'word: {word.text+\" \"}\\tupos: {word.upos}\\txpos: {word.xpos}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
